Автор: Jaynam Переводчик: AI Обновлено 27 августа 2024 года

## 2. Взгляд на программирование

Добро пожаловать в удивительный мир компьютеров! Прежде чем погружаться в программирование, важно узнать больше о компьютерах. Давайте рассмотрим некоторые основные аспекты, связанные с программированием.

### 2.1 Как компьютер обрабатывает информацию

**(1) Введение в двоичный код**

Вы когда-нибудь задумывались, как ваш компьютер, планшет или смартфон знают, как выполнять множество крутых задач? Все дело в том, как они обрабатывают информацию. Давайте начнем с основ этого процесса, начиная с того, что называется «двоичным кодом». Сначала подумайте о том, как мы представляем информацию в нашей повседневной жизни.

**Способы представления информации в нашем мире**

В нашей повседневной жизни мы используем разные способы представления и передачи информации. Например:

- Языки: Будь то письменный или устный, мы можем общаться и передавать информацию с помощью символов, основанных на буквах, словах и звуках. Каждая буква имеет определенную форму и значение, и каждое слово или предложение, которое мы произносим, несет конкретное значение.
- Графические символы и картинки: Дорожные знаки, рисунки и фотографии могут содержать много информации.
- Звуки: Мы также используем разные звуки для передачи значений. Звонок дверей может сказать нам, что пришел гость. Сирена предупреждает нас о какой-либо опасности.

Таким же образом, компьютеры нуждаются в специальной системе для понимания и обработки информации. Эта система называется двоичным кодом, который представляет собой универсальный язык, состоящий всего из двух символов: 0 и 1. Эти символы работают вместе, чтобы представлять все виды данных, от чисел и букв до картинок и звуков. «Двоичный» относится к «двоичной системе», которая использует только два символа (0 и 1). А «код» означает использование набора символов или правил для кодирования, декодирования или передачи информации таким образом, чтобы она была понятной или пригодной для использования, особенно в контексте компьютеров и обработки информации.

**Двоичная система**

В нашей повседневной жизни мы обычно используем числа на основе 10 цифр: от 0 до 9. Давайте сделаем немного простую математику. Если вы прибавите 1 к 0, результат будет 1. Прибавьте 1 снова, и получите 2. Если прибавить 1 к 0 девять раз, мы используем все 10 цифр от 0 до 9. Но что если прибавить 1 десять раз к 0? Результат будет 10. Давайте подробнее рассмотрим "10". Оно состоит из "1" и "0", при этом "1" находится слева от "0". Однако, если сложить две цифры числа "10", то есть 1 плюс 0, получаем 1. Тем не менее, это простое сложение не объясняет, как "10" представляет число, равное 10 в нашей десятичной системе.

В повседневной жизни, если не указано иное, мы используем "десятичную систему". Слово "десятичная" происходит от латинского слова "decem", что означает "десять". "Десятичная система" относится к числовой системе, основанной на степенях десяти. В десятичной системе каждое место имеет значение в десять раз больше значения места справа от него. Каждая цифра в числе представляет собой разное место значения, которое в десятичной системе является степенью десяти.

Например, рассмотрим число 345:

- Цифра 5 находится в "единицах" (10^0, десять в степени ноль), представляя 5.
- Цифра 4 находится в "десятках" (10^1, десять в степени один), представляя 4 × 10 = 40.
- Цифра 3 находится в "сотнях" (10^2, десять в степени два), представляя 3 × 100 = 300.

Сложив эти значения (300 + 40 + 5), мы получаем итоговое значение 345.

Теперь давайте рассмотрим двоичную систему. В отличие от десятичной системы, которая использует десять цифр, двоичная система использует только две цифры: 0 и 1. Каждая цифра в двоичном числе представляет собой степень 2, а не 10.

Например, в двоичном числе 101:

- Самая правая цифра (1) находится в "единицах" (2^0, два в степени ноль), что представляет 1.
- Средняя цифра (0) находится в "двойках" (2^1, два в степени один), что представляет 0 × 2 = 0.
- Левая цифра (1) находится в "четверках" (2^2, два в степени два), что представляет 1 × 4 = 4.

Чтобы найти десятичное значение двоичного числа 101, сложите эти значения: 4 (из "четверок") + 0 (из "двойок") + 1 (из "единиц") = 5.

Таким образом, двоичное число 101 равно десятичному числу 5.

**Почему компьютеры используют двоичную систему**

Десятичная система является наиболее распространённой и используется в повседневном счёте и арифметике. У человека десять пальцев, что делает счёт в десятичной системе интуитивным и простым. Эта естественная методика счёта, вероятно, повлияла на развитие десятичной системы. Хотя десятичная система удобна для нас, людей, она не является наилучшим выбором для компьютеров. Вместо этого двоичная система лучше подходит для таких электронных машин. Причина заключается в "анатомии" компьютеров.

Компьютеры используют электрические схемы, которые могут быть либо включены, либо выключены. Эти два состояния естественно представлены двоичными цифрами 0 и 1. Двоичная система идеально подходит для компьютеров, поскольку она полностью соответствует их электрическим сигналам включения/выключения. Используя двоичную систему, компьютеры могут эффективно обрабатывать и хранить данные.

ЦПУ, ключевой компонент компьютера, полагается на транзисторы как фундаментальные единицы. Транзистор — это крошечный и простой элемент схемы, который может действовать как электронные переключатели и усиливать слабые электрические сигналы. Современные ЦПУ содержат миллиарды транзисторов, которые функционируют как переключатели для обработки и хранения данных. Аналогичным образом, оперативная память (RAM), графические процессоры (GPU) и твердотельные накопители (SSD) также используют транзисторы.

В компьютере почти все транзисторы функционируют как переключатели, что означает, что они работают только в двух состояниях: включено и выключено. Поэтому естественно и просто использовать 1 для состояния "включено" и 0 для состояния "выключено".

**(2) Как двоичный код представляет данные**

Чтобы понять, как двоичный код представляет данные, давайте сначала рассмотрим, как ПК обрабатывает и хранит информацию. Когда программа работает, её серия инструкций загружается в оперативную память (RAM). Наряду с инструкциями от других программ, они ставятся в очередь на выполнение. ЦПУ непрерывно извлекает инструкции из этой очереди, одну за другой. Каждый раз, когда ЦПУ извлекает инструкцию, он считывает данные из RAM, а иногда инструкция включает чтение или запись на жёсткий диск. Современные ЦПУ могут обрабатывать до 64 бит данных одновременно, тогда как более старые ЦПУ могли обрабатывать только до 32 бит.

Это вызывает несколько вопросов: сколько бит данных должен считывать или записывать компьютер из RAM за раз? Сколько бит следует использовать в качестве основной единицы? Если бы ЦПУ считывал или записывал только 1 бит за раз, это было бы чрезвычайно неэффективно и затратно по времени из-за высокой частоты операций. Поэтому 64-битный ЦПУ обычно считывает или записывает 64 бита данных за раз, а 32-битный ЦПУ обрабатывает 32 бита за раз для оптимального баланса между производительностью и эффективностью. RAM обычно использует 8 бит в качестве основной единицы.

Выбор 8-битной единицы для RAM был обусловлен историческими, технологическими и стандартизационными факторами. Ранние компьютеры использовали различные размеры единиц данных, но по мере развития технологий 8-битная единица стала более распространённой. Этот размер стал оптимальным компромиссом между эффективностью и возможностями, особенно для представления символов и данных.

**Кодировка ASCII**

ASCII (Американский стандартный код для обмена информацией) — это стандарт кодировки символов, используемый для представления текста в компьютерах и других текстовых устройствах. Этот стандарт является основой для многих современных схем кодировки. ASCII использует 7-битные бинарные числа, что позволяет закодировать 128 уникальных символов, коды которых варьируются от 0 до 127.

Стандартные символы ASCII включают:

- Управляющие символы (0–31):

  Это непечатаемые символы, которые управляют обработкой текста. Примеры включают:

  - `0` (NUL): Символ NULL
  - `9` (TAB): Горизонтальная табуляция
  - `10` (LF): Перевод строки (новая строка)
  - `13` (CR): Возврат каретки

- Печатаемые символы (32–127):

  Это видимые символы, такие как буквы, цифры, знаки препинания и символы. Примеры включают:

  - `32` (SPACE): Пробел
  - `65` (A): Заглавная буква A
  - `97` (a): Строчная буква a
  - `48` (0): Цифра 0
  - `33` (!): Восклицательный знак

Коды ASCII используют 7 битов, что позволяет закодировать 128 символов, но современные компьютеры используют 8 битов как базовую единицу данных. Эта 8-битная единица, или байт, позволяет закодировать 256 символов, что обычно достаточно для английского и других западных языков. Для более сложных языков используются дополнительные байты для представления символов, что обеспечивает эффективное использование памяти и хранения. Хотя ASCII сам по себе требует только 7 битов, 8-битное представление является обычным в компьютерах, где дополнительный бит обычно установлен в 0. Например, код ASCII для заглавной буквы "A" равен 65 (десятичный) или 01000001 (бинарный), где дополнительный бит равен нулю.

**Символы математических операторов на компьютере**

На стандартной клавиатуре вы можете заметить отсутствие некоторых математических символов, таких как знак умножения (×). Вместо этого компьютеры часто используют альтернативные символы для упрощения. Вот несколько распространенных примеров:

- Умножение: `*`
- Деление: `/`
- Остаток от деления: `%`
- Возведение в степень: `**` (часто используется в языках программирования, таких как Python), и в некоторых случаях `^` (чаще используется в калькуляторах).

Эти символы применяются для выполнения арифметических операций в различных программных средах и калькуляторах.

**Единицы измерения данных**

Современные компьютеры используют 8 бит в качестве основной единицы данных, известной как байт (B). Вот обзор других общих единиц измерения данных и их преобразований:

- Бит (b, строчная буква): Наименьшая единица данных в вычислениях. Представляет собой двоичную цифру, которая может быть либо `0`, либо `1`.
- Байта (B, заглавная буква): Основная единица измерения данных, состоящая из 8 бит.

Для более крупных единиц измерения используются две разные системы преобразования: бинарная и десятичная. Бинарные единицы основаны на степенях 2, в то время как десятичные единицы используют степени 10. В вычислениях обычно используются бинарные единицы, в то время как десятичные единицы часто применяются в маркетинге. Начиная с байта, большая бинарная единица составляет 2^10 (1024) раз больше предыдущей единицы, в то время как большая десятичная единица составляет 10^3 (1000) раз больше предыдущей единицы.

Единицы измерения на основе бинарной системы:

- Килобайт (KB): 1 KB = 1 024 байта (2^10 байт).
- Мегабайт (MB): 1 MB = 1 024 KB = 1 048 576 байт (2^20 байт).
- Гигабайт (GB): 1 GB = 1 024 MB = 1 073 741 824 байта (2^30 байт).
- Терабайт (TB): 1 TB = 1 024 GB = 1 099 511 627 776 байт (2^40 байт).

Единицы измерения на основе десятичной системы:

- Килобайт (KB): 1 KB = 1 000 байт (10^3 байт).
- Мегабайт (MB): 1 MB = 1 000 KB = 1 000 000 байт (10^6 байт).
- Гигабайт (GB): 1 GB = 1 000 MB = 1 000 000 000 байт (10^9 байт).
- Терабайт (TB): 1 TB = 1 000 GB = 1 000 000 000 000 байт (10^12 байт).

Чтобы ясно различать бинарные единицы измерения от десятичных, IEC (Международная электротехническая комиссия) ввела префиксы "би", которые обозначают "бинарные" единицы. Эти единицы имеют такие же значения, как и бинарные преобразования, но имеют более различимые названия.

- Кибибайт (KiB): 1 KiB = 1 024 байта (2^10 байт).
- Мебибайт (MiB): 1 MiB = 1 024 KiB = 1 048 576 байт (2^20 байт).
- Гибибайт (GiB): 1 GiB = 1 024 MiB = 1 073 741 824 байта (2^30 байт).
- Тебибайт (TiB): 1 TiB = 1 024 GiB = 1 099 511 627 776 байт (2^40 байт).

Десятичные преобразования часто используются в маркетинге, поскольку они дают более крупные числа для той же емкости хранения. Например, жесткий диск, обозначенный как имеющий 500 GB (десятичный), на самом деле имеет 500 000 000 000 байт, что приблизительно равно 465 GiB (бинарный).

**Двоичные представления различных типов данных**

Все данные, независимо от их типа, в конечном итоге представляют собой двоичную форму. Данные обрабатываются и хранятся как последовательности нулей и единиц в компьютерах. Для хранения текста, изображений, аудио и других типов данных нужно «перевести» их в двоичный код, что называется «кодированием». Когда нужно использовать эти данные в удобочитаемом виде, программное обеспечение интерпретирует двоичный код и преобразует его в текст, изображения и другие форматы, которые мы можем понять, что называется «декодированием».

Вот несколько примеров кодирования различных типов данных:

- **Текст**: Символы представляются с использованием стандартов кодирования, таких как ASCII или Unicode (Универсальный код). Каждому символу присвоен уникальный двоичный код. Например, код ASCII для 'A' — 01000001 в двоичном представлении.
- **Числа**: Числа представляются с использованием различных двоичных форматов, таких как целые числа (числа без дробных частей, например, `-3`, `0`) и числа с плавающей точкой (числа с дробными частями, например, `3.14`, `-0.01`). Например, целое число 5 представлено как 00000101 в 8-битном двоичном представлении.
- **Аудио**: Аудио данные обычно представляют собой серию образцов. Эти образцы захватываются через равные промежутки времени и кодируются в двоичном виде. Например, 16-битный аудиобразец может быть представлен как 16-битное двоичное число.
- **Изображения**: Изображения состоят из пикселей, каждый из которых имеет значения цвета. В градационном изображении каждый пиксель может быть представлен 8-битным двоичным числом, указывающим его интенсивность. В цветном изображении каждый пиксель обычно представлен комбинацией двоичных чисел, соответствующих его компонентам красного, зелёного и синего цвета.
- **Видео**: Видео представляет собой последовательность изображений (кадров) и часто включает аудио. Каждый кадр — это изображение, представленное в двоичном виде, а кадры отображаются быстро друг за другом, создавая иллюзию движения.
- **Файлы и форматы**: Разные форматы файлов (такие как JPEG для изображений, MP3 для аудио, MP4 для видео) определяют конкретные способы кодирования данных. Эти форматы используют двоичный код для структурирования и сжатия данных эффективно.

**Сжатие данных**

Представьте, что у вас есть огромная куча игрушек, которые нужно упаковать в маленькую коробку. Сжатие данных похоже на то, как вы находите способ упаковать и уменьшить игрушки, чтобы они все поместились в коробку, не потеряв ни одной. В компьютерах это означает уменьшение размера файлов, чтобы они занимали меньше места и их было быстрее отправлять или хранить.

Вот простой пример алгоритма Run-Length Encoding (RLE): если у вас есть последовательность английских букв "AAAAAAADDDDCCVSSSSSSSSS", которая состоит из 23 символов и занимает 23 байта места. Мы можем посчитать, сколько раз каждая буква повторяется, и заменить эти буквы на количество повторений и саму букву: "7A4D2C1V9S". Новая последовательность состоит из 5 чисел и 5 букв. Мы можем использовать один байт для представления каждого числа и использовать ASCII код для букв, что в сумме составит 10 байт. Когда нам нужно распаковать последовательность, мы читаем число и букву, а затем повторяем букву в соответствии с числом. Таким образом, мы уменьшаем размер данных и используем меньше места.

Для разных типов данных мы обычно выбираем разные алгоритмы сжатия, так как каждый из них имеет свои преимущества и ограничения.